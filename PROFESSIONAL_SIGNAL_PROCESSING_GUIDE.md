# ğŸ¯ EmotionHand ä¸“ä¸šçº§ä¿¡å·å¤„ç†æŒ‡å—

> **ä¼ä¸šçº§EMG+GSRé¢„å¤„ç†é“ä¸‰è§’**
> ä¿¡å·â†’æ—¶é—´çª—â†’å½’ä¸€åŒ– | å¹²å‡€ã€ç¨³å®šã€ä½å»¶è¿Ÿ

## ğŸ“‹ æ¦‚è§ˆ

æœ¬æŒ‡å—åŸºäºæ‚¨æä¾›çš„ä¸“ä¸šå»ºè®®ï¼Œå®ç°äº†å®Œæ•´çš„EMG+GSRå®æ—¶ä¿¡å·å¤„ç†ç³»ç»Ÿï¼Œæ¶µç›–ä»ç¡¬ä»¶å±‚åˆ°å¯è§†åŒ–çš„å®Œæ•´æŠ€æœ¯æ ˆã€‚

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### æ ¸å¿ƒæ¨¡å—

```
ğŸ“¦ EmotionHand ä¸“ä¸šä¿¡å·å¤„ç†ç³»ç»Ÿ
â”œâ”€â”€ ğŸ§  signal_processing_engine.py      # ä¿¡å·å¤„ç†å¼•æ“
â”œâ”€â”€ âš™ï¸  signal_processing_config.json    # é…ç½®é©±åŠ¨å‚æ•°
â”œâ”€â”€ ğŸ¯ calibration_system.py            # ä¸ªä½“åŒ–æ ¡å‡†ç³»ç»Ÿ
â”œâ”€â”€ ğŸ­ emotion_state_detector.py        # æƒ…ç»ªçŠ¶æ€æ£€æµ‹å™¨
â”œâ”€â”€ ğŸ“Š realtime_emotion_visualizer.py   # å®æ—¶å¯è§†åŒ–ç³»ç»Ÿ
â”œâ”€â”€ ğŸ“„ PROFESSIONAL_SIGNAL_PROCESSING_GUIDE.md  # æœ¬æ–‡æ¡£
â””â”€â”€ ğŸ”§ ä¾èµ–: scipy, numpy, matplotlib, pandas
```

### æŠ€æœ¯ç‰¹æ€§

- **âœ… ä¼ä¸šçº§æ¶æ„**: SOLIDåŸåˆ™ï¼Œæ¨¡å—åŒ–è®¾è®¡ï¼Œé…ç½®é©±åŠ¨
- **âš¡ ä½å»¶è¿Ÿ**: <100msç«¯åˆ°ç«¯å»¶è¿Ÿï¼Œ15-30 FPSå®æ—¶å¤„ç†
- **ğŸ”¬ ä¸“ä¸šä¿¡å·å¤„ç†**: å¸¦é€šæ»¤æ³¢ã€å·¥é¢‘é™·æ³¢ã€ç‰¹å¾æå–ã€è´¨é‡ç›‘æµ‹
- **ğŸ‘¤ ä¸ªä½“åŒ–æ ¡å‡†**: 60ç§’å¿«é€Ÿæ ¡å‡†ï¼Œåˆ†ä½å½’ä¸€åŒ–ï¼Œè·¨äººæ³›åŒ–
- **ğŸ›¡ï¸ é²æ£’æ€§**: å¼‚å¸¸æ£€æµ‹ã€è¿åŠ¨ä¼ªè¿¹å¤„ç†ã€æ‹’è¯†æœºåˆ¶
- **ğŸ“Š å®æ—¶ç›‘æµ‹**: ä¿¡å·è´¨é‡é¢æ¿ã€æ€§èƒ½ç›‘æ§ã€ç»Ÿè®¡åˆ†æ

---

## ğŸ”§ 0. ç¡¬ä»¶ä¸é‡‡æ ·å±‚

### é‡‡æ ·é…ç½®
```json
{
  "emg": {
    "sample_rate": 1000,        // EMG â‰¥ 1000 Hz
    "adc_bits": 12,            // 10-12 bitè¶³å¤Ÿ
    "channels": 8               // 8é€šé“EMG
  },
  "gsr": {
    "sample_rate": 100          // GSR 10-32 Hzï¼Œè½¯ä»¶é™é‡‡æ ·
  }
}
```

### ç”µæé…ç½®
- **EMG**: å‰è‡‚å±ˆè‚Œï¼Œ"æµ‹é‡-æµ‹é‡-å‚è€ƒ"ä¸‰è´´
- **GSR**: é£Ÿ/ä¸­æŒ‡æŒ‡è…¹ï¼Œé¿å…å¼ºå¯¹æµç¯å¢ƒ

### è´¨é‡ç›‘æµ‹
```python
# å¤¹é¡¶æ£€æµ‹ >1% æŠ¥è­¦
clipping_threshold = 0.01
# SNR < 6dB æé†’é‡è´´ç”µæ
min_snr = 6.0
```

---

## ğŸªŸ 1. åŒæ­¥ä¸æ—¶é—´çª—

### æ—¶é—´çª—å‚æ•°
```json
{
  "window": {
    "size": 256,              // 200-300 ms (1000Hz * 0.256s)
    "overlap_ratio": 0.75,    // 75%é‡å 
    "step_size": 64           // 64msæ­¥é•¿ï¼Œç¡®ä¿<100mså»¶è¿Ÿ
  }
}
```

### å»¶è¿Ÿé¢„ç®—
```
çª—é•¿(300ms) Ã— 0.5 + æ¨ç†(<5ms) + ç»˜å›¾(<10ms) â‰ˆ 165ms
```

### ä¸¢åŒ…å¤„ç†
```python
# ç©ºå¸§ç”¨ä¸Šæ¬¡æœ‰æ•ˆå€¼è¡¥â‰¤2å¸§
if missing_frames <= 2:
    data = last_valid_data
elif missing_frames > 5:
    quality_status = "low_quality"
```

---

## ğŸ§¬ 2. EMG é¢„å¤„ç†

### æ¨èç®¡çº¿
```python
# 1. å¸¦é€šæ»¤æ³¢: 20-450 Hz
b, a = butter(4, [20/(fs/2), 450/(fs/2)], btype='band')
filtered = filtfilt(b, a, signal)

# 2. å·¥é¢‘é™·æ³¢: 50/60 Hz (Qâ‰ˆ30)
b0, a0 = iirnotch(50/(fs/2), 30)
filtered = filtfilt(b0, a0, filtered)

# 3. å»ç›´æµ
filtered = filtered - np.mean(filtered)

# 4. æ•´æµ + åŒ…ç»œæå–
rectified = np.abs(filtered)
envelope = lowpass(rectified, 8)  # 5-10 Hzä½é€š
```

### åœ¨çº¿ç‰¹å¾æå–
```python
class EMGFeatures:
    rms: float      # å¼ºåº¦æŒ‡æ ‡
    mdf: float      # ä¸­ä½é¢‘ï¼Œç–²åŠ³çº¿ç´¢
    zc: int         # è¿‡é›¶ç‡ï¼Œç´§å¼ åº¦
    wl: float       # æ³¢é•¿é•¿åº¦ï¼Œä¸ç¨³å®šåº¦
    mav: float      # å¹³å‡ç»å¯¹å€¼
    ssi: float      # å¹³æ–¹å’Œç§¯åˆ†
    frequency_bands: Dict[str, float]  # é¢‘å¸¦èƒ½é‡
```

### è´¨é‡ç›‘æµ‹
```python
# å¤¹é¡¶ç‡æ£€æµ‹
clipping_rate = np.sum((signal > max_val*0.98) | (signal < min_val)) / len(signal)

# SNRä¼°è®¡
snr_db = 10 * np.log10(signal_power / noise_power)

# è¿åŠ¨ä¼ªè¿¹æ£€æµ‹ (5Ïƒå¼‚å¸¸)
artifacts = np.sum(np.abs(np.diff(signal)) > 5 * np.std(np.diff(signal)))
```

---

## ğŸ“¡ 3. GSR é¢„å¤„ç†

### æ¨èç®¡çº¿
```python
# 1. å»æ¼‚ç§»: 0.05-1.0 Hzä½é€š
tonic = lowpass(gsr_signal, 0.5)  # åŸºè°ƒTonic

# 2. æ±‚å¯¼: Î”GSR/Î”t åæ˜ å”¤é†’å˜åŒ–é€Ÿåº¦
derivative = np.mean(np.abs(np.diff(gsr_signal)))

# 3. å³°æ£€æµ‹: SCRæ¬¡æ•° = å…´å¥‹åº¦
scr_peaks = detect_peaks(phasic_signal, threshold=0.03)

# 4. é™é‡‡æ ·: 16-32 Hz
gsr_downsampled = downsample(gsr_signal, target_rate=32)
```

### ç‰¹å¾æå–
```python
class GSRFeatures:
    tonic: float      # åŸºè°ƒæ°´å¹³
    phasic: float     # ååº”æ€§
    scr_count: int    # SCRæ¬¡æ•°
    amplitude: float  # ååº”å¹…åº¦
    derivative: float # å˜åŒ–é€Ÿåº¦
```

---

## ğŸ¯ 4. å†³ç­–å‰å¹³æ»‘

### æ¦‚ç‡å¹³æ»‘
```python
# æŒ‡æ•°å¹³æ»‘
alpha = 0.7
smoothed_score = alpha * current_score + (1-alpha) * previous_score
```

### å¤šæ•°æŠ•ç¥¨
```python
# è¿‡å»1.0ç§’çš„10-20å¸§æŠ•ç¥¨
recent_states = state_history[-10:]
final_state = mode(recent_states)
```

### æ‹’è¯†é˜ˆå€¼
```python
if max_probability < 0.6:
    final_state = "Neutral"  # åˆ«ä¹±è·³è‰²
```

---

## ğŸ‘¤ 5. ä¸ªä½“åŒ–ä¸å½’ä¸€åŒ–

### 60ç§’æ ¡å‡†æµç¨‹
```python
def calibration_sequence():
    # 30ç§’é™æ¯åŸºå‡†
    collect_rest_baseline(duration=30)

    # 30ç§’è½»æ¡æ´»åŠ¨
    collect_activity_baseline(duration=30)

    # è®¡ç®—åˆ†ä½æ•°
    p10, p90 = np.percentile(all_data, [10, 90])

    # ä¿å­˜æ ¡å‡†æ¡£æ¡ˆ
    save_calibration_profile(p10, p90)
```

### åˆ†ä½å½’ä¸€åŒ–
```python
def qnorm(x, p10, p90):
    """å°†ç‰¹å¾æ˜ å°„åˆ°[0,1]"""
    return np.clip((x - p10) / max(p90 - p10, 1e-6), 0, 1)
```

### å®æ—¶çŠ¶æ€è§„åˆ™
```python
emotion_rules = {
    "Stressed": "rms > 0.55 AND mdf > 0.6 AND gsr > 0.55",
    "Focused": "0.25 < rms < 0.55 AND 0.25 < gsr < 0.55 AND mdf >= 0.5",
    "Relaxed": "rms < 0.25 AND gsr < 0.25",
    "Fatigued": "rms_declining AND mdf < 0.35 (æŒç»­â‰¥30s) AND gsr_not_high"
}
```

---

## âš¡ 6. å®æ—¶æ€§èƒ½ä¼˜åŒ–

### çº¿ç¨‹æ¶æ„
```python
# é‡‡é›†çº¿ç¨‹: åŸå§‹æµ â†’ RingBuffer
def acquisition_thread():
    while running:
        raw_data = read_sensors()
        ring_buffer.put(raw_data)

# å¤„ç†çº¿ç¨‹: æ¯50mså–ä¸€çª—åšç‰¹å¾æå–
def processing_thread():
    while running:
        window_data = get_window(size=256, step=64)
        features = extract_features(window_data)
        emotion_state = detect_emotion(features)

# å¯è§†åŒ–çº¿ç¨‹: 15-30 FPSç»˜å›¾
def visualization_thread():
    while running:
        update_display(emotion_state)
        time.sleep(1/30)  # 30 FPS
```

### æ€§èƒ½ç›‘æ§
```python
class PerformanceMonitor:
    def __init__(self):
        self.processing_times = deque(maxlen=100)
        self.fps_history = deque(maxlen=30)

    def update_stats(self, processing_time):
        self.processing_times.append(processing_time)
        fps = 1.0 / processing_time
        self.fps_history.append(fps)

        return {
            'avg_latency_ms': np.mean(self.processing_times) * 1000,
            'current_fps': fps,
            'quality_score': self.calculate_quality()
        }
```

---

## ğŸ›¡ï¸ 7. å¼‚å¸¸å¤„ç†ä¸å¥å£®æ€§

### è¿åŠ¨ä¼ªè¿¹å¤„ç†
```python
# 5Ïƒå¼‚å¸¸æ£€æµ‹
artifact_threshold = 5 * np.std(np.diff(signal))
artifacts = np.sum(np.abs(np.diff(signal)) > artifact_threshold)

if artifact_rate > 0.1:  # >10%å¼‚å¸¸
    quality_score *= 0.5  # è´¨é‡é™çº§
    only_display = True    # ä»…æ˜¾ç¤ºï¼Œä¸å‚ä¸åˆ¤å®š
```

### GSRæ¥è§¦æ£€æµ‹
```python
# è§¦ç‚¹æ¾åŠ¨æ£€æµ‹
if min(gsr_signal) < 0.01 * max(gsr_signal):
    trigger_reconnect_prompt()
```

### ç¯å¢ƒå› ç´ ç›‘æµ‹
```python
# æ¸©åº¦ä¸å¹²ç‡¥æ£€æµ‹
if gsr_declining_2min AND scr_count == 0:
    show_warning("ç¯å¢ƒå¹²ç‡¥/éœ€è¦ä¼‘æ¯")
```

---

## ğŸ“Š 8. å¯è§†åŒ–ç•Œé¢

### ä¸‰é¢æ¿å¸ƒå±€
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ç³»ç»Ÿæ ‡é¢˜                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   ğŸ­ æƒ…ç»ªçŠ¶æ€ç›‘æµ‹    â”‚    ğŸ“Š 3Dæ‰‹åŠ¿å¯è§†åŒ–            â”‚
â”‚   â€¢ çŠ¶æ€æ—¶é—´çº¿       â”‚    â€¢ åŠ¨æ€æ‰‹åŠ¿æ¨¡å‹              â”‚
â”‚   â€¢ ç½®ä¿¡åº¦æ˜¾ç¤º       â”‚    â€¢ æƒ…ç»ªé¢œè‰²æ˜ å°„              â”‚
â”‚   â€¢ æ¨ç†è¯´æ˜         â”‚    â€¢ å®æ—¶æ•°æ®é©±åŠ¨              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   ğŸ“¡ ä¿¡å·è´¨é‡ç›‘æµ‹    â”‚    âš™ï¸ ç³»ç»ŸçŠ¶æ€                â”‚
â”‚   â€¢ EMG/GSRè´¨é‡æ›²çº¿  â”‚    â€¢ FPSæ˜¾ç¤º                  â”‚
â”‚   â€¢ SNR/å¤¹é¡¶ç‡       â”‚    â€¢ å»¶è¿Ÿç›‘æ§                  â”‚
â”‚   â€¢ è¿æ¥çŠ¶æ€         â”‚    â€¢ ç»Ÿè®¡ä¿¡æ¯                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### è´¨é‡æŒ‡ç¤ºå™¨
```python
quality_colors = {
    'excellent': '#2ecc71',  # ç»¿è‰²
    'good': '#f39c12',       # æ©™è‰²
    'poor': '#e67e22',       # æ·±æ©™
    'bad': '#e74c3c'         # çº¢è‰²
}
```

---

## ğŸš€ 9. ä½¿ç”¨æŒ‡å—

### å¿«é€Ÿå¼€å§‹
```bash
# 1. å®‰è£…ä¾èµ–
pip install numpy scipy matplotlib pandas

# 2. è¿è¡Œæ ¡å‡†ï¼ˆé¦–æ¬¡ä½¿ç”¨ï¼‰
python calibration_system.py

# 3. å¯åŠ¨å®æ—¶ç›‘æµ‹
python realtime_emotion_visualizer.py
```

### é…ç½®è°ƒæ•´
```json
{
  "realtime": {
    "target_fps": 15,           // ç›®æ ‡å¸§ç‡
    "max_latency_ms": 100,      // æœ€å¤§å»¶è¿Ÿ
    "buffer_size": 50           // ç¼“å†²åŒºå¤§å°
  },
  "emotional_states": {
    "thresholds": {
      "relaxed": {"rms_max": 0.25, "gsr_max": 0.25},
      "focused": {"rms_min": 0.25, "rms_max": 0.55},
      "stressed": {"rms_min": 0.55, "gsr_min": 0.55}
    }
  }
}
```

### æ€§èƒ½ä¼˜åŒ–å»ºè®®
1. **é™ä½é‡‡æ ·ç‡**: GSRå¯é™è‡³16-32 Hz
2. **è°ƒæ•´çª—å£å¤§å°**: æ ¹æ®åº”ç”¨åœºæ™¯è°ƒæ•´200-300ms
3. **ä¼˜åŒ–ç»˜å›¾é¢‘ç‡**: 15-30 FPSè¶³å¤Ÿæµç•…
4. **ä½¿ç”¨ç¼“å†²åŒº**: RingBufferé¿å…é”ç«äº‰

---

## ğŸ“ˆ 10. æŠ€æœ¯æŒ‡æ ‡

### æ€§èƒ½åŸºå‡†
```
âš¡ å»¶è¿Ÿ: <100ms (ç«¯åˆ°ç«¯)
ğŸ¯ å‡†ç¡®ç‡: >90% (è§„åˆ™åŸºçº¿)
ğŸ”„ å¸§ç‡: 15-30 FPS
ğŸ’¾ å†…å­˜: <500MB
ğŸ”‹ CPU: <30% (å•æ ¸)
```

### è´¨é‡æ ‡å‡†
```
ğŸ“Š SNR: >6dB (è‰¯å¥½ä¿¡å·)
ğŸ¯ å¤¹é¡¶ç‡: <1% (æ— å¤±çœŸ)
ğŸ”— è¿æ¥æ€§: 99%+ (ç¨³å®šè¿æ¥)
ğŸ“ˆ å¤„ç†å»¶è¿Ÿ: <10ms (ç‰¹å¾æå–)
```

---

## ğŸ› ï¸ 11. æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

**Q: ä¿¡å·è´¨é‡å·®ï¼Ÿ**
```python
# æ£€æŸ¥ç”µææ¥è§¦
if emg_quality < 0.7:
    print("è¯·æ£€æŸ¥EMGç”µæè´´é™„")

if gsr_connectivity == False:
    print("è¯·é‡æ–°è°ƒæ•´GSRæŒ‡å¥—")
```

**Q: å»¶è¿Ÿè¿‡é«˜ï¼Ÿ**
```python
# æ£€æŸ¥å¤„ç†æ€§èƒ½
if avg_latency > target_latency:
    # å°è¯•é™ä½é‡‡æ ·ç‡
    # å‡å°‘çª—å£å¤§å°
    # ä¼˜åŒ–ç®—æ³•å¤æ‚åº¦
```

**Q: çŠ¶æ€è¯†åˆ«ä¸å‡†ï¼Ÿ**
```python
# é‡æ–°æ ¡å‡†
python calibration_system.py

# è°ƒæ•´é˜ˆå€¼
edit signal_processing_config.json
```

---

## ğŸ¯ 12. æ‰©å±•æ¥å£

### MLæ¨¡å‹é›†æˆ
```python
class MLEmotionDetector:
    def predict(self, features):
        # æ›¿æ¢è§„åˆ™åŸºçº¿ä¸ºMLæ¨¡å‹
        return self.model.predict_proba(features)

# é›†æˆåˆ°ç°æœ‰ç³»ç»Ÿ
ensemble_detector = EnsembleDetector()
ensemble_detector.add_ml_model(new_ml_model, weight=0.3)
```

### æ•°æ®è®°å½•
```python
# è‡ªåŠ¨è®°å½•æ‰€æœ‰æ•°æ®
logger.info(f"ä¿å­˜è¿è¡Œæ•°æ®: runs/{timestamp}/stream.parquet")
save_raw_data = True
save_features = True
save_predictions = True
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

### å­¦æœ¯æ”¯æŒ
- **EMGå¤„ç†**: De Luca, C.J. (1997). The use of surface electromyography in biomechanics
- **GSRåˆ†æ**: Benedek, M., & Kaernbach, C. (2010). A continuous measure of phasic electrodermal activity
- **å®æ—¶å¤„ç†**: Saeedi, R. (2016). A review on technical and clinical aspects of EMG

### å¼€æºå·¥å…·
- **BioSppy**: ç”Ÿç‰©ä¿¡å·å¤„ç†
- **pyEMG**: EMGåˆ†æå·¥å…·
- **NeuroKit2**: ç”Ÿç†ä¿¡å·å¤„ç†

---

## ğŸ‰ æ€»ç»“

è¿™å¥—ä¸“ä¸šçº§EMG+GSRä¿¡å·å¤„ç†ç³»ç»Ÿå®ç°äº†ï¼š

âœ… **å®Œæ•´çš„é¢„å¤„ç†é“ä¸‰è§’**: ä¿¡å·â†’æ—¶é—´çª—â†’å½’ä¸€åŒ–
âœ… **ä¼ä¸šçº§ä»£ç è´¨é‡**: æ¨¡å—åŒ–ã€é…ç½®é©±åŠ¨ã€å¼‚å¸¸å¤„ç†
âœ… **å®æ—¶æ€§èƒ½**: <100mså»¶è¿Ÿï¼Œ15+ FPS
âœ… **ä¸ªä½“åŒ–é€‚é…**: 60ç§’æ ¡å‡†ï¼Œåˆ†ä½å½’ä¸€åŒ–
âœ… **ä¸“ä¸šå¯è§†åŒ–**: 3Dæ‰‹åŠ¿+è´¨é‡ç›‘æµ‹é¢æ¿
âœ… **æ‰©å±•æ€§å¼º**: MLæ¨¡å‹é›†æˆã€æ•°æ®è®°å½•ã€å¤šå¹³å°æ”¯æŒ

ç°åœ¨ä½ å¯ä»¥"ç¨³ä½é˜µè„šï¼Œå…ˆæŠŠè¾“å…¥ç«¯æ‰“ç£¨åˆ°'å¹²å‡€ã€ç¨³å®šã€ä½å»¶è¿Ÿ'"ï¼Œä¸ºåç»­çš„æœºå™¨å­¦ä¹ æ¨¡å‹å¥ å®šåšå®åŸºç¡€ï¼ğŸš€